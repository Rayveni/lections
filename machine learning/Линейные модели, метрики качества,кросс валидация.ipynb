{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    " Важной характеристикой матрицы, а также линейного преобразования, заданного этой матрицей, является\n",
    "спектр — набор собственных векторов и соответствующих собственных значений.\n",
    "Собственным вектором линейного преобразования $A$ называется такой ненулевой вектор  $x\\in V$ , что для\n",
    "некоторого $\\lambda\\in R$ выполняется $A x\\in \\lambda x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Методы оптимизации\n",
    "* **Метод имитации отжига** <br>\n",
    "функция anneal (англ. отжиг) в модуле optimize/позволяет оптимизировать **негладкие** функции\n",
    "библиотеки SciPy.\n",
    "* **Метод Нелдера-Мида**, он же **симплекс метод** использвуется для оптимизации функций негладких и зашумленных\n",
    "<br>Метод Нелдера-Мида является методом\n",
    "оптимизации по умолчанию в функции SciPy.optimize.minimize,особенно хорошо работает, если перед ним применить метод грубой оптимизации(например поиск по сетке)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение на размеченных данных\n",
    "* $\\mathbb{X}$ -пространство объектов\n",
    "* $\\mathbb{Y}$ -пространство ответов\n",
    "* $x=(x^1,...,x^d)$ -признаковое описание\n",
    "* $X=(x_i,y_i)^l_{i=1}$ -обучающая выборка\n",
    "* $ a(x)$ -алгоритм ,модель\n",
    "* $ Q(a,X)$ -функционал ошибки алгоритма на выборке $X$\n",
    "* обучение:$a(x)=argmin\\,Q(a,X),a\\in A$\n",
    "\n",
    "То есть,цель обучения минимизировать функциал ошибки, подобрав соответвующий алгоритм из семейства A\n",
    "## Линейные модели\n",
    "Рассмотрим задачу о предсказании прибыли по данным продаж предыдущего месяца.<br>\n",
    "Видим, что можно провести прямую, более менее угадывающую зависимость между признаками.\n",
    "\n",
    "![linear_model](../img/linear_model.png)\n",
    "\n",
    "Но как правило признаков несколько(то есть имеем дело с многомерными выборками)<br>\n",
    "**общий вид линейной модели**:\n",
    "$$a(x)=w_o+\\sum^d_{j=1}w_jx^j$$\n",
    "$w_i$-веса модели перед соотвествующими признаками $w_0$- свободный коэффициент, он же сдвиг, он же **bias**<br>\n",
    "другой вариант записи(без сдвига):\n",
    "$$a(x)=\\sum^{d+1}_{j=1}w_jx^j=\\langle w,x \\rangle$$\n",
    "### Среднеквадратичная ошибка\n",
    "$$Q(a,X)=\\frac{1}{l}\\sum^l_{i=1}(a(x_i)-y_i)^2$$\n",
    "матричная запись:\n",
    "$$Q(a,X)=\\frac{1}{l}||Xw-y||^2$$ где $l$-число объектов,$X$-матрица признаков,$w$ -вектор весов,$y$-вектор ответов\n",
    "### Линейная регрессия\n",
    "$$ Q (w,x)=\\frac{1}{l}\\sum_{l=1}^{l} (\\langle w{,}x \\rangle-y_i)^2 \\to \\min\\limits_{w}    $$\n",
    "То есть задача найти модель, с минимальной ошибкой, то есть переходим к задаче оптимизации.<br>\n",
    "Среднеквадратичная ошибка-выпуклая(следовательно один минимум) и гладкая функция (значит можно рассчитать градиент).\n",
    "#### Градиентный спуск.\n",
    "1. инициализация вектора весов(например нулями) $w^0=0$\n",
    "2. цикл по $t=1,2,3...$ -итерации <br>\n",
    "$w^t=w^{t-1}-\\eta_t \\nabla Q(w^{t-1},X)$,если $||w^t-w^{t-1}||<\\epsilon$, то завершить<br>\n",
    "где $\\nabla Q$ -градиент,<br>$\\eta_t$ -шаг градиентного спуска(параметр)<br><br>\n",
    "То есть,обновляем вектор весов до сходимости<br>\n",
    "Функционал качества в зависимости от итерации,видим, что начиная с определенного номера выходит на ассимптоду:\n",
    "\n",
    "![quality](../img/quality.png)\n",
    "Очень важно в градиентном спуске выбрать размер шага $\\eta$:<br>\n",
    "Если взять шаг маленьким, то градиенту понадобится много итераций для достижения минимума,если взять слишком большим- начнет перескакивать точку минимума.\n",
    "\n",
    "![gradientstep](../img/gradientstep.png)\n",
    "Неплохо работает:$\\eta_t=\\frac{k}{t}$,где $k$- константа(надо подбирать)\n",
    "#### Стохастический градиентный спуск(cокращенное наименование:**SGD**)\n",
    "1. инициализация вектора весов(например нулями) $w^0=0$\n",
    "2. цикл по $t=1,2,3...$ -итерации <br>\n",
    "выбрать случайный объект $x_i$ из $X$<br>\n",
    "$w^t=w^{t-1}-\\eta_t \\nabla Q(w^{t-1},{x_i})$,если $||w^t-w^{t-1}||<\\epsilon$, то завершить<br>\n",
    "\n",
    "Таким образом,на каждом шаге уменьшаем ошибку не на всей выборке, а на случайном объекте.<br>\n",
    "Преимущества:\n",
    "* быстрее выполняется один шаг\n",
    "* не требует хранения выборки в памяти и таким образом позволяет работать с очень большими данными\n",
    "* подходит для онлайн-обучения\n",
    "### Линейная классификация\n",
    "задача бинарной классификации:$\\mathbb{Y}=\\{-1,+1\\}$<br>\n",
    "**линейный классификатор**\n",
    "$$a(x)=sign\\,\\sum^{d+1}_{j=1}w_jx^j=sign\\,\\langle w,x \\rangle$$\n",
    "\n",
    "Линейный классификатор разделяет два класса гиперплоскостью:\n",
    "\n",
    "![geomlinclass](../img/geomlinclass.png)\n",
    "расстояние от точки до гиперплоскости со знаком:<br>$\\frac{|\\langle w,x \\rangle|}{||w||}$\n",
    "\n",
    "То есть классификатор вначале измеряет расстояние от точки до гиперплоскости и далее смотрит лишь на знак.<br>\n",
    "**отступ**<br>\n",
    "* $M_i=y_i\\langle w,x_i \\rangle, y_i=\\{-1,+1\\}$ \n",
    "* $M_i>0$-классификатор дает верный ответ\n",
    "* $M_i<0$классификатор ошибается\n",
    "\n",
    "Чем дальше отступ от нуля, тем больше уверенности<br>\n",
    "**функционал качества**\n",
    "доля неправильных ответов:<br>\n",
    "$Q(a,X)=\\frac{1}{l}\\sum^l_{i=1}[a(x_i)\\not= y_i]$<br>\n",
    "доля неправильных ответов через отсутп:<br>\n",
    "$Q(a,X)=\\frac{1}{l}\\sum^l_{i=1}[M_i<0]$<br>\n",
    "\n",
    "Эта функция разрывна в нуле и из за этого ее нельзя оптимизировать градиентными методами(можно воспользоваться методами негладкой оптимизации , но они сложны в реализации и не дают гарантии сходимости к локальному оптимуму)<br>\n",
    "Поэтому будем оптимизировать любую гладкую оценку пороговой функции:$$[M<0]\\leq \\tilde{L}(M)$$\n",
    "Оценим через нее функционал ошибки:\n",
    "$$Q(a,x)\\leq \\tilde{Q}(a,X)=\\frac{1}{l}\\sum^l_{i=1}\\tilde{L}(M_i)$$\n",
    "Таким образом,мы **надеемся**,что минимизируя верхнюю оценку и минимизируем то, что она оценивает,но ,разумееется нет никаких гарантий.<br> примеры оценок:\n",
    "* логистическая $\\tilde{L}(M)=ln(1+exp(-M)$\n",
    "* экспоненициальная $\\tilde{L}(M)=exp(-M)$\n",
    "* кусочно линейная $\\tilde{L}(M)=max(0,1-M)$\n",
    "\n",
    "### Проблема переобучения\n",
    "* **недообучение**- плохое качество и на обучении и на новых данных\n",
    "* **переобучение**- хорошее качество  на обучении и плохое на новых данных ,то есть модель хорошо описывает текущие данные , но обладает плохой обобщающей способностью<br>\n",
    "\n",
    "Как выявить переобучение?:\n",
    "* отложеннаая выборка -данные , на которых не обучались\n",
    "* кросс валиадация(пояснение ниже)\n",
    "* меры сложности модели\n",
    "\n",
    "##### Регуляризация(контроль сложности модели)\n",
    "нужна для:\n",
    "* борьба со сложностью модели\n",
    "* борьба с линейностью признаков (мультиколлинеарность)\n",
    "\n",
    "Симптомом переобучения являются большие веса при коээфициентах.И поэтому будем штрафовать модель за большие веса.<br>\n",
    "**квадратичный регуляризатор** $$ ||w||_2 =\\sum_{j=1}^{d} w_{j}^2 $$\n",
    "новый функционал ошибки :\n",
    "$$Q(w,X)+ \\lambda ||w||^2 \\to \\min\\limits_{w}  $$\n",
    "То есть, мы будем стремиться получить ошибку как можно меньше , при этом стараться не сильно увеличив веса\n",
    "* чем больше $\\lambda$, тем ниже сложность модели\n",
    "* чем меньше $\\lambda$, тем выше риск переобучения\n",
    "* выбор $\\lambda$ по кросс валидации\n",
    "\n",
    "**виды регуляризаторов**<br>\n",
    "* $ ||w||_2 =\\sum_{j=1}^{d} w_{j}^2  -L_2 регуляризатор$  **ridge** (гребневый) -**частый выбор** <br>\n",
    "гладкий и выпуклый(не усложняет оптимизацию)\n",
    "\n",
    "* $ ||w||_1 =\\sum_{j=1}^{d} |w_{j}| -L_1 регуляризатор $  **lasso**\n",
    "\n",
    "$L_1$-регуляризатор:\n",
    "* Негладкий(сложнее оптимизировать)\n",
    "* Некоторые веса оказываются нулевыми(за счет этого можно отбирать признаки)\n",
    "\n",
    "##### Отложенная выборка\n",
    "* разбиваем выборку на 2 части\n",
    "* на одной обучаем алгоритм\n",
    "* на второй измеряем качество\n",
    "\n",
    "обычно берут разбиение : 70%/30% ,80%/20% \n",
    "* (+) обучаем алгоритм один раз (подходит если данных очень много)\n",
    "* (-) завим от разбиения(результат качества сильно зависит от того , как выбираем отложенную выборку)\n",
    "\n",
    "улучшение -много отложенных выборок\n",
    "\n",
    "* разбиваем выборку n раз\n",
    "* усредним получившиеся оценки и получим итоговую оценку\n",
    "\n",
    "по прежнему нет гарантии того, что каждый объект побывает в обучающей выборке.<br>\n",
    "Более системный подход- кроссвалидация.\n",
    "##### Кросс-Валидация \n",
    "* разбиваем выборку на k блоков\n",
    "* каждый блок по очереди выступает как тестовый , на остальных обучаемся\n",
    "* усредним их и получим оценку качество\n",
    "![crossval](../img/crossval.png)\n",
    "мало блоков:\n",
    "*(+) надежные оценки\n",
    "*(-) смещенные оценки\n",
    "\n",
    "много блоков:\n",
    "*(-) ненадежные оценки\n",
    "*(+) несмещенные оценки\n",
    "\n",
    "* обычно:k=3,5,10\n",
    "\n",
    "* чем больше выборка, тем меньше нужно $k$\n",
    "\n",
    "##### Совет\n",
    "* перемешивайте выборку(если не предсказываете будующее)\n",
    "### Гиперпараметры\n",
    "\n",
    "те параметры, которые нельзя настроить по обучающей выборку<br>\n",
    "примеры: параметры регуляризации, стень полинома\n",
    "\n",
    "более обще:\n",
    "* функционал ошибки\n",
    "* алгоритм\n",
    "\n",
    "схема подбора:\n",
    "* разбиваем выборку на обучающую и контроль\n",
    "* на обучающей выборке по кроссвалиации обучаем и сравниваем  алгоритм\n",
    "* проверяем на контрольной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Метрики качества в задачах регрессии\n",
    "зачем нужны:\n",
    "\n",
    "* для задания функционала ошибки(используется при обучении)\n",
    "* для подбора гиперпараметров( используется для измерения качества на кросс валидации)\n",
    "* для оценивая итоговой модели(пригодна получившая модель для решения бизнес задачи)\n",
    "## Метрики качества в задачах регрессии\n",
    "\n",
    "* $MSE(a,X)=\\frac{1}{l}\\sum_{i=1}^l(a(x_i)-y_i)^2$ - среднеквадратичная ошибка ,легко оптизируется,но\n",
    "<br> подстраивается под выбросы(что плохо)\n",
    "*  $MAE(a,X)=\\frac{1}{l}\\sum_{i=1}^l|a(x_i)-y_i|$ -считается модуль отклонения, а не квадрат <br>штраф за выборсы ниже\n",
    "* коэффициент детерминации $$ R^2(a,X)=1-\\frac{\\sum_{i=1}^{l} (a(x_i)-y_i)^2}{\\sum_{i=1}^{l} (y_i-\\bar{y})^2} ,$$\n",
    "$ \\bar{y}=\\frac{1}{l}\\sum_{i=1}^{l} y_i $ -средний ответ\n",
    "\n",
    "-некоторая модификация среднеквадратичной ошибки<br>\n",
    "Показывает долю дисперсии, объясненной общей моделью\n",
    "* $0 \\leq R^2 \\leq 1$ для разумных моделей\n",
    "* $ R^2 =1$ идеальная модель\n",
    "* $ R^2 =0$ модель на уровне константной\n",
    "* $ R^2 < 0$ модель хуже константной\n",
    "\n",
    "\n",
    "**квантильная ошибка ** <br> используется если ошибки прогноза(перепрогноз или недопрогноз имеют разную цену\n",
    "\n",
    "$\\rho_{\\tau}(a,X)=\\frac{1}{l}\\sum_{i=1}^l ((\\tau-1)[y_i<a(x_i)]+\\tau[y_i\\geq a(x_i)])(y_i-a(x_i))$,<br>\n",
    "если $\\tau$ близко к нулю ,мы боимся перепрогноза, если $\\tau$ ,близко к 1 -боимся недопрогноза\n",
    "\n",
    "#### вероятностный смысл\n",
    "\n",
    "* **MSE** -средний ответ\n",
    "* **MAE** - медиана ответов\n",
    "* **квантильная ошибка** - $\\tau$ квантиль\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Метрики качества в задачах классификации\n",
    "* **доля правильных ответов(accuracy)**:<br> $$accuracy(a,X)=\\frac{1}{l}\\sum_{i=1}^{l} [a(x_i)=y_i]$$<br>проблема- несбаллансированные выборки<br> Для этого введем $q_0$ -доля объектов самого крупного класса выборки<br>\n",
    "и для разумных алгоритмов $accuracy \\in [q_0,1]$\n",
    "##### Матрица ошибок\n",
    "\n",
    "|   |  y=1 | y=-1  |  \n",
    "|---|---|---|---|---|\n",
    "| a(x)=1  | True Positive(TP)  | False Positive(FP)  |  \n",
    "|a(x)=-1   | False Negative (FN)  | True Negative (TN)  |\n",
    "\n",
    "* **точность** (насколько верно алгоритм относит объекты к первому классу) $$precision(a,X)=\\frac{TP}{TP+FP}$$\n",
    "* **Полнота**(как много истинных объектов первого класса выделяет алгоритм) $$recall(a,X)=\\frac{TP}{TP+FN}$$\n",
    "* **F мера - объедиение точности и полноты** $$F=\\frac{2*precison*recall}{precison+recall}$$ <br>**расширенная версия F меры**\n",
    "$$F_\\beta=(1+\\beta^2)*\\frac{precision+recall}{\\beta^2*precision+recall}$$ <br> если $\\beta=0.5 $ получим важнее полнота,если $\\beta=2 $ то важнее точность\n",
    "\n",
    "### Качество оценок классификатора\n",
    "\n",
    "* **PR -кривая **<br>Ось X - полнота<br>Ось Y - точность<br>точки-классификаторы при определённых порогах\n",
    "![prsq](../img/prsq.png)\n",
    "<br> Левая точка (0,0) <br> Правая точка (1,r),где **r** -доля положительных объектов <br>Для идеального классификатора проходит через (1,1)<br> **AUC-PRC** -площадь под PR-кривой\n",
    "* **POC -кривая **<br>Ось X - FalsePositiveRate$$FPR=\\frac{FP}{FP+TN}$$<br>Ось Y - TruePositiveRate $$TPR=\\frac{TP}{TP+FN}$$<br>\n",
    "![rocsq](../img/rocsq.png)\n",
    "**AUC-ROC** -площадь под ROC-кривой\n",
    "\n",
    "идеальный алгоритм даст площади AUC-PRC и AUC-ROC равными 1, худший -0.5 <br>\n",
    "Площадь под ROC кривой **не зависит** от баланса классов и обладает следующей интерпритацией:\n",
    "Площадь под ROC кривой = вероятности того, что если выбрать случайный положительный и случайный отрицательный объект из выборки,то положительный объект получит оценку принадлежности выше чем отрицательный.\n",
    "\n",
    "<br>**AUC-PRG** -выразительнее в случае дисбаланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры (python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, datasets,linear_model, metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разовое разбиение данных на обучение и тест с помощью train_test_split\n",
    "на iris датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris=datasets.load_iris()\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(iris.data, iris.target, \n",
    "                                                                                     test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold\n",
    "важно:возвращает индексы, а не данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  y\n",
       "0  0  0\n",
       "1  1  0\n",
       "2  2  0\n",
       "3  3  0\n",
       "4  4  0\n",
       "5  5  1\n",
       "6  6  1\n",
       "7  7  1\n",
       "8  8  1\n",
       "9  9  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(range(10))\n",
    "target = np.array([0] * 5 + [1] * 5)\n",
    "pd.DataFrame(list(zip(X,target)),columns=['X','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на k фолдов(частей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4 5 6 7 8] [2 9]\n",
      "[0 1 2 3 5 7 8 9] [4 6]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 1 2 3 4 6 7 9] [5 8]\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in model_selection.KFold( n_splits = 5, shuffle = True, random_state = 1).split(X):\n",
    "    print( train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedKFold\n",
    "разбиваем на k частей , учитывая балланс классов(стараемся его сохранить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[1 2 3 4 5 6 8 9] [0 7]\n",
      "[0 2 3 4 5 7 8 9] [1 6]\n",
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n"
     ]
    }
   ],
   "source": [
    "# target- метки классов\n",
    "target = np.array([0] * 5 + [1] * 5)\n",
    "for train_indices, test_indices in model_selection.StratifiedKFold(n_splits=5, shuffle = True, random_state = 0).split(X,target):\n",
    "    print (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 1 0 2 6 7 5] [9 8]\n",
      "[6 1 9 2 5 4 7 8] [3 0]\n",
      "[4 1 6 3 9 7 8 0] [2 5]\n",
      "[8 1 7 5 6 0 3 2] [9 4]\n",
      "[0 5 6 4 9 7 1 3] [8 2]\n",
      "[5 7 8 3 4 1 2 0] [9 6]\n",
      "[8 2 4 1 6 3 5 7] [9 0]\n",
      "[8 1 0 2 7 9 5 6] [4 3]\n",
      "[5 0 1 6 2 3 4 8] [9 7]\n",
      "[8 6 3 4 7 9 0 1] [5 2]\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in model_selection.ShuffleSplit( n_splits = 10, test_size = 0.2).split(X):\n",
    "    print (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 8 9 5 1 0 7 3] [4 6]\n",
      "[6 8 7 2 0 1 3 9] [4 5]\n",
      "[2 5 6 8 3 9 1 4] [7 0]\n",
      "[9 8 1 3 2 0 7 5] [4 6]\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in model_selection.StratifiedShuffleSplit(n_splits = 4, test_size = 0.2).split(X,target):\n",
    "    print (train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9] [0]\n",
      "[0 2 3 4 5 6 7 8 9] [1]\n",
      "[0 1 3 4 5 6 7 8 9] [2]\n",
      "[0 1 2 4 5 6 7 8 9] [3]\n",
      "[0 1 2 3 5 6 7 8 9] [4]\n",
      "[0 1 2 3 4 6 7 8 9] [5]\n",
      "[0 1 2 3 4 5 7 8 9] [6]\n",
      "[0 1 2 3 4 5 6 8 9] [7]\n",
      "[0 1 2 3 4 5 6 7 9] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_index in model_selection.LeaveOneOut().split(X):\n",
    "    print (train_indices, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blobs = datasets.make_blobs(centers = 2, cluster_std = 5.5, random_state=1)\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(blobs[0], blobs[1], \n",
    "                                                                                    test_size = 0.3,\n",
    "                                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#создание объекта - классификатора\n",
    "ridge_classifier = linear_model.RidgeClassifier(random_state = 1)\n",
    "#обучение классификатора\n",
    "ridge_classifier.fit(train_data, train_labels)\n",
    "#применение обученного классификатора\n",
    "ridge_predictions = ridge_classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#оценка качества классификации\n",
    "metrics.accuracy_score(test_labels, ridge_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0854443  -0.07273219]]\n",
      "[-0.31250723]\n"
     ]
    }
   ],
   "source": [
    "print(ridge_classifier.coef_)\n",
    "print(ridge_classifier.intercept_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31250723])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_classifier.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "log_regressor.fit(train_data, train_labels)\n",
    "lr_predictions = log_regressor.predict(test_data)\n",
    "# выводим вероятности принадлежности к классам\n",
    "lr_proba_predictions = log_regressor.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.866666666667\n"
     ]
    }
   ],
   "source": [
    "print (metrics.accuracy_score(test_labels, lr_predictions))\n",
    "print (metrics.accuracy_score(test_labels, ridge_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества по cross-validation\n",
    "#### cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8  0.9  0.9  0.9  1.   1.   0.7  0.9  0.9  0.8]\n",
      "[ 0.7  0.9  0.9  0.9  1.   1.   0.7  0.9  0.9  0.8]\n"
     ]
    }
   ],
   "source": [
    "#For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used.\n",
    "ridge_scoring = model_selection.cross_val_score(ridge_classifier, blobs[0], blobs[1], scoring = 'accuracy', cv = 10)\n",
    "print(ridge_scoring)\n",
    "lr_scoring = model_selection.cross_val_score(log_regressor, blobs[0], blobs[1], scoring = 'accuracy', cv = 10)\n",
    "print(lr_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge mean:0.8800000000000001, max:1.0, min:0.7, std:0.08717797887081348\n",
      "Log mean:0.8700000000000001, max:1.0, min:0.7, std:0.10049875621120892\n"
     ]
    }
   ],
   "source": [
    "print ('Ridge mean:{}, max:{}, min:{}, std:{}'.format(ridge_scoring.mean(), ridge_scoring.max(), \n",
    "                                                     ridge_scoring.min(), ridge_scoring.std()))\n",
    "print ('Log mean:{}, max:{}, min:{}, std:{}'.format(lr_scoring.mean(), lr_scoring.max(), \n",
    "                                                   lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score с заданными scorer и cv_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge mean:0.8500000000000001, max:0.95, min:0.75, std:0.07905694150420946\n",
      "Log mean:0.875, max:0.9, min:0.85, std:0.025000000000000022\n"
     ]
    }
   ],
   "source": [
    "scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "cv_strategy = model_selection.StratifiedShuffleSplit(n_splits = 4, test_size = 0.2)\n",
    "ridge_scoring =model_selection.cross_val_score(ridge_classifier, blobs[0], blobs[1], scoring = scorer, cv = cv_strategy)\n",
    "lr_scoring = model_selection.cross_val_score(log_regressor, blobs[0], blobs[1], scoring = scorer, cv = cv_strategy)\n",
    "print ('Ridge mean:{}, max:{}, min:{}, std:{}'.format(ridge_scoring.mean(), ridge_scoring.max(), \n",
    "                                                     ridge_scoring.min(), ridge_scoring.std()))\n",
    "print ('Log mean:{}, max:{}, min:{}, std:{}'.format(lr_scoring.mean(), lr_scoring.max(), \n",
    "                                                   lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества в задачах классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels, ridge_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  4],\n",
       "       [ 0, 12]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_labels, ridge_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(test_labels, ridge_predictions, pos_label = 1),metrics.precision_score(test_labels, ridge_predictions, pos_label = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.77777777777777779)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(test_labels, ridge_predictions, pos_label = 1),metrics.recall_score(test_labels, ridge_predictions, pos_label = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87500000000000011, 0.8571428571428571)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_labels, ridge_predictions, pos_label = 0),metrics.f1_score(test_labels, ridge_predictions, pos_label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.78      0.88        18\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.90      0.87      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( metrics.classification_report(test_labels, ridge_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJhWSJKkTJhWSJKkTXwHtlySvXaDnCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xada49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(test_labels, lr_proba_predictions[:,1])\n",
    "pylab.plot(fpr, tpr, label = 'linear model')\n",
    "pylab.plot([0, 1], [0, 1], '--', color = 'grey', label = 'random')\n",
    "pylab.xlim([-0.05, 1.05])\n",
    "pylab.ylim([-0.05, 1.05])\n",
    "pylab.xlabel('False Positive Rate')\n",
    "pylab.ylabel('True Positive Rate')\n",
    "pylab.title('ROC curve')\n",
    "pylab.legend(loc = \"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889\n",
      "0.958333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(test_labels, ridge_predictions))\n",
    "print(metrics.roc_auc_score(test_labels, lr_proba_predictions[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PR AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.average_precision_score(test_labels, ridge_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log_loss\n",
    "чем меньше метрика, тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35185364928848134"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(test_labels, lr_proba_predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFkCAYAAACXcsmHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xae1acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, target, coef = datasets.make_regression(n_features = 2, n_informative = 1, n_targets = 1, \n",
    "                                              noise = 5., coef = True, random_state = 2)\n",
    "pylab.scatter(list(map(lambda x:x[0], data)), target, color = 'r')\n",
    "pylab.scatter(list(map(lambda x:x[1], data)), target, color = 'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(data, target,  \n",
    "                                                                                     test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -52.37232463   41.95683853  -61.47026695  -84.32102748  126.64909941\n",
      "  -21.47606913  -45.27502383  -11.18242389   -0.74051877   18.17188553\n",
      "   49.41686419   19.66406455  -22.64686884   64.70214251   13.31981235\n",
      "   11.06961035  -27.02798161   10.33267887   64.19559505   14.76930132\n",
      "  -35.32062686   17.64282734   51.87072011  -80.80239408   39.70663436\n",
      "   22.13032804  -36.69728864   34.35183007  -10.06708677  -44.51417742]\n",
      "[ -40.82558721   46.29712728  -57.174697    -82.64534324  126.53807404\n",
      "  -17.646268    -48.44284229  -12.07920494    2.23871454   20.07924255\n",
      "   57.02410697   26.93589538  -17.39687478   69.58999605   14.8479796\n",
      "   27.74126588  -23.94660126    9.45092868   70.96938999    7.73232465\n",
      "  -42.59743261   20.85628259   52.66666264  -78.4516698    39.0068076\n",
      "   21.27381335  -26.37803673   40.25097095   -7.87593508  -54.50132513]\n",
      "4.64436347664\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = linear_model.LinearRegression()\n",
    "linear_regressor.fit(train_data, train_labels)\n",
    "predictions = linear_regressor.predict(test_data)\n",
    "print (test_labels)\n",
    "print (predictions)\n",
    "print(metrics.mean_absolute_error(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -4.070071498779695, std: 1.0737104492890204\n"
     ]
    }
   ],
   "source": [
    "linear_scoring = model_selection.cross_val_score(linear_regressor, data, target, scoring = 'neg_mean_absolute_error', \n",
    "                                                  cv = 10)\n",
    "print ('mean: {}, std: {}'.format(linear_scoring.mean(), linear_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.070071498779695, std: 1.0737104492890204\n"
     ]
    }
   ],
   "source": [
    "scorer = metrics.make_scorer(metrics.mean_absolute_error, greater_is_better = True)\n",
    "linear_scoring = model_selection.cross_val_score(linear_regressor, data, target, scoring=scorer, \n",
    "                                                  cv = 10)\n",
    "print ('mean: {}, std: {}'.format(linear_scoring.mean(), linear_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38.58531354  -0.31014876]\n",
      "0.289180847617\n",
      "y = 38.59*x1 + -0.31*x2\n"
     ]
    }
   ],
   "source": [
    "print(linear_regressor.coef_)\n",
    "print(linear_regressor.intercept_)\n",
    "print (\"y = {:.2f}*x1 + {:.2f}*x2\".format(linear_regressor.coef_[0], linear_regressor.coef_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.154478246666398, std: 1.0170354384993348\n",
      "y = 37.74*x1 + -0.00*x2\n"
     ]
    }
   ],
   "source": [
    "lasso_regressor = linear_model.Lasso(random_state = 3)\n",
    "lasso_regressor.fit(train_data, train_labels)\n",
    "lasso_predictions = lasso_regressor.predict(test_data)\n",
    "lasso_scoring = model_selection.cross_val_score(lasso_regressor, data, target, scoring = scorer, cv = 10)\n",
    "print ('mean: {}, std: {}'.format(lasso_scoring.mean(), lasso_scoring.std()))\n",
    "print (\"y = {:.2f}*x1 + {:.2f}*x2\".format(lasso_regressor.coef_[0], lasso_regressor.coef_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5066204243124615"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test_labels, lasso_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.71039851558551"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(test_labels, lasso_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7193005267764612"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(metrics.mean_squared_error(test_labels, lasso_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848357338405328"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(test_labels, lasso_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Линейные модели рекомендации\n",
    "* масштабирование признаков <br>\n",
    "вычисляем среднее значение и стандартное отклонение <br>\n",
    "$$\\mu_j=\\frac{1}{l}\\sum_{i=1}^{l} x_i^j $$ $$\\sigma_j=\\sqrt{\\sum_{i=1}^{l}( x_i^j-\\mu_j)^2}$$\n",
    "**Стандартизация(нормализация)**$$x_i^j:=\\frac{ x_i^j-\\mu_j}{\\sigma_j}$$ **масштабирование на отрезок [0,1]**$$m_j=min(x_1^j,...,x_l^j)$$$$M_j=max(x_1^j,...,x_l^j)$$$$x_i^j:=\\frac{ x_i^j-m_j}{M_j-m_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование спрямляющих пространств\n",
    "к примеру: если модель плохо описывает данные , можно попробовать добавть полиномы высого порядка(при степени равной 2 -добавляем новые признаки , равные квадратам исходных+ попарные произведения <br>**логарифмирование**$$x_i \\to ln(x_i+1)$$$$x_i \\to ln(|x_i|+1)$$\n",
    "\n",
    "### Категориальные признаки\n",
    "используем бинарное кодирование(если признак принимает n значений, добавляем n признаков и кодируем каждое значение вектором из 0 и 1\n",
    "### Несбаллансированные выборки\n",
    "*undersampling( выкидываем часть объектов)\n",
    "*oversampling( дополням часть объектов)\n",
    "\n",
    "*стратификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import  datasets, linear_model, metrics,model_selection\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(iris.data, iris.target, \n",
    "                                                                                     test_size = 0.3,random_state = 0)\n",
    "#создаем модель\n",
    "classifier = linear_model.SGDClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_jobs', 'fit_intercept', 'l1_ratio', 'epsilon', 'shuffle', 'power_t', 'eta0', 'loss', 'random_state', 'warm_start', 'verbose', 'average', 'learning_rate', 'class_weight', 'penalty', 'alpha', 'n_iter'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#задаем параметры для перебора\n",
    "parameters_grid = {\n",
    "    'loss' : ['hinge', 'log', 'squared_hinge', 'squared_loss'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'n_iter' : list(range(5,10)),\n",
    "    'alpha' : np.linspace(0.0001, 0.001, num = 5),\n",
    "}\n",
    " \n",
    "#cv =model_selection.StratifiedShuffleSplit(n_splits =10, test_size = 0.2).split(train_data, train_labels)\n",
    "#cv = model_selection.StratifiedShuffleSplit(train_labels, n_iter = 10, test_size = 0.2, random_state = 0)\n",
    "cv=model_selection.StratifiedShuffleSplit(n_splits = 10, test_size = 0.2)#.split(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров и оценка качества\n",
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_cv = model_selection.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'loss': ['hinge', 'log', 'squared_hinge', 'squared_loss'], 'penalty': ['l1', 'l2'], 'n_iter': [5, 6, 7, 8, 9], 'alpha': array([ 0.0001 ,  0.00032,  0.00055,  0.00078,  0.001  ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='squared_hinge', n_iter=9, n_jobs=1,\n",
       "       penalty='l1', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909523809524\n",
      "{'loss': 'squared_hinge', 'penalty': 'l1', 'n_iter': 9, 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (grid_cv.best_score_)\n",
    "print (grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "randomized_grid_cv = model_selection.RandomizedSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv, n_iter = 20, \n",
    "                                                   random_state = 0)\n",
    "randomized_grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871428571429\n",
      "{'loss': 'squared_hinge', 'penalty': 'l1', 'n_iter': 8, 'alpha': 0.00077500000000000008}\n"
     ]
    }
   ],
   "source": [
    "print (randomized_grid_cv.best_score_)\n",
    "print (randomized_grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,FunctionTransformer,OneHotEncoder\n",
    "#создаем стандартный scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data, train_labels)\n",
    "scaled_train_data = scaler.transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.066666666666666666"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "#создаем pipeline из двух шагов: scaling и классификация\n",
    "pipeline = Pipeline(steps = [('scaling', scaler), ('classifier', classifier)])\n",
    "pipeline.fit(train_data, train_labels)\n",
    "metrics.mean_absolute_error(test_labels, pipeline.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['steps', 'classifier__random_state', 'classifier__shuffle', 'classifier__epsilon', 'classifier__average', 'classifier__power_t', 'classifier__class_weight', 'classifier__n_jobs', 'classifier__penalty', 'classifier__learning_rate', 'classifier__verbose', 'scaling__copy', 'scaling__with_mean', 'scaling', 'classifier__warm_start', 'scaling__with_std', 'classifier__n_iter', 'classifier__l1_ratio', 'classifier', 'classifier__loss', 'classifier__eta0', 'classifier__fit_intercept', 'classifier__alpha'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'regression__loss' : ['huber', 'epsilon_insensitive', 'squared_loss', ],\n",
    "    'regression__n_iter' : [3, 5, 10, 50], \n",
    "    'regression__penalty' : ['l1', 'l2', 'none'],\n",
    "    'regression__alpha' : [0.0001, 0.01],\n",
    "    'scaling__with_mean' : [0., 0.5],\n",
    "}\n",
    "grid_cv = model_selection.GridSearchCV(pipeline, parameters_grid, scoring = 'mean_absolute_error', cv = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaling', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('classifier',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "         eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "         learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "         penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "         warm_start=False))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ести нужно разделять признаки:\n",
    "estimator = Pipeline(steps = [       \n",
    "    ('feature_processing', FeatureUnion(transformer_list = [        \n",
    "            #binary\n",
    "            ('binary_variables_processing', FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                    \n",
    "            #numeric\n",
    "            ('numeric_variables_processing',Pipeline(steps = [\n",
    "                ('selecting', FunctionTransformer(lambda data: data[:, numeric_data_indices])),\n",
    "                ('scaling', StandardScaler(with_mean = 0))            \n",
    "                        ])),\n",
    "        \n",
    "            #categorical\n",
    "            ('categorical_variables_processing',Pipeline(steps = [\n",
    "                ('selecting', FunctionTransformer(lambda data: data[:, categorical_data_indices])),\n",
    "                ('hot_encoding', OneHotEncoder(handle_unknown = 'ignore'))            \n",
    "                        ])),\n",
    "        ])),\n",
    "    ('model_fitting', classifier)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
